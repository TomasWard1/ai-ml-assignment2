{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network on MNIST Grayscale\n",
    "### By Tomas Ward\n",
    "Building a convolutional neural network (CNN) to classify digits from the grayscale MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from ..excersises.excersise1 import plot_losses\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "(mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = mnist.load_data()\n",
    "plt.imshow(mnist_x_train[0])\n",
    "\n",
    "# Reshape the data to make it suitable for a CNN (# images, image size in pixels (x), image size in pixels (y), # channels)\n",
    "trainX = mnist_x_train.reshape((mnist_x_train.shape[0], 28, 28, 1 )) / 255\n",
    "testX = mnist_x_test.reshape((mnist_x_test.shape[0], 28, 28, 1)) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing: One hot encode the labels\n",
    "trainY = pd.get_dummies(mnist_y_train)\n",
    "testY = pd.get_dummies(mnist_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model architecture\n",
    "cnn_model = Sequential()\n",
    "\n",
    "# First convolutional layer with 32 3x3 filters which will reduce image dimensions.\n",
    "# Maxpooling added to reduce size but maintain the important data\n",
    "cnn_model.add(Conv2D(32,(3, 3),activation='relu',input_shape=(28, 28, 1),use_bias=False))\n",
    "cnn_model.add(MaxPooling2D((2, 2), strides=1))\n",
    "\n",
    "# Second convolutional layer with 64 3x3 filters which will reduce image dimensions.\n",
    "cnn_model.add(Conv2D(64,(3, 3),activation='relu',input_shape=(28, 28, 1),use_bias=False))\n",
    "cnn_model.add(MaxPooling2D((2, 2), strides=1))\n",
    "\n",
    "# Last convolutional layer with 128 3x3 filters which will reduce image dimensions.\n",
    "cnn_model.add(Conv2D(128,(3, 3),activation='relu',input_shape=(28, 28, 1),use_bias=False))\n",
    "cnn_model.add(MaxPooling2D((2, 2), strides=1))\n",
    "\n",
    "# Flatten layer to convert the data into vector form for the Dense network\n",
    "cnn_model.add(Flatten())\n",
    "\n",
    "# Input dense layer with x neurons.\n",
    "# TODO: Figue out how many input neurons\n",
    "cnn_model.add(Dense(40, activation='relu')),\n",
    "\n",
    "#Hidden layers\n",
    "cnn_model.add(Dense(40, activation='relu')),\n",
    "cnn_model.add(Dropout()) # To prevent overfitting\n",
    "\n",
    "# Output layer with 10 neurons for classification of 10 digits.\n",
    "cnn_model.add(Dense(40, activation='softmax')),\n",
    "\n",
    "optimizer = Adam(learning_rate=0.003)\n",
    "cnn_model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model, plotting the loss in real time\n",
    "# TODO: add early stopping\n",
    "history = cnn_model.fit(np.array(mnist_x_train), np.array(mnist_y_train), epochs=100,validation_split = 0.2, callbacks=[plot_losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run metrics with validation set\n",
    "# TODO: Fix this\n",
    "scores=cnn_model.evaluate(np.array(valX),np.array(valY))\n",
    "print(\"Loss:\",scores[0])\n",
    "print(\"Accuracy\",scores[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model with the test set\n",
    "pred_y=cnn_model.predict(np.array(mnist_x_test))\n",
    "pred_y=np.round(pred_y).astype(int).reshape(1,-1)[0]\n",
    "\n",
    "# Compute the confusion matrix to monitor model performance\n",
    "m=confusion_matrix(pred_y,mnist_y_test)\n",
    "sns.heatmap(m, annot=True) # TODO: Change colors and add titles to all graphs\n",
    "\n",
    "# TODO: Get accuracy and loss scores for test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Comparison\n",
    "## FNN vs CNN\n",
    "Is the added complexity of a CNN worth it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random image reader\n",
    "This codeblock picks a random image from the MNIST Grayscale test set and runs it through the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
